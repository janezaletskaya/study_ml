{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVEjA98muAWu"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OYt1RIlWuAWv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5XVYw4MuAWw"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global_mean = 0\n",
        "# for imgs, labels in train_data_loader:\n",
        "#   global_mean += imgs.sum()\n",
        "\n",
        "# global_mean /= len(train_mnist_data) * 28 * 28\n",
        "\n",
        "# global_var = 0\n",
        "# for imgs, labels in train_data_loader:\n",
        "#   global_var += ((imgs - global_mean) ** 2).sum()\n",
        "\n",
        "# global_var /= len(train_mnist_data) * 28 * 28\n",
        "# global_std = torch.sqrt(global_var)"
      ],
      "metadata": {
        "id": "zZ7-8Kzkz-fY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_mean, global_std)"
      ],
      "metadata": {
        "id": "m8e_M_A30AlK",
        "outputId": "7aee8e00-3bc5-4279-f5e6-c1a56230efeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1307) tensor(0.3081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8iCeyQijuAWw",
        "outputId": "74061db0-b9e5-4d04-f86d-f935c1130d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.1307], std=[0.3081])\n",
        "])\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=transform, download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEcLML6uAWw"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fl = nn.Flatten()\n",
        "out = fl(torch.randn(32, 1, 28, 28))\n",
        "out.size()"
      ],
      "metadata": {
        "id": "_YL5HZRM0XjS",
        "outputId": "2679b021-098d-408e-93e6-e60de3b3e174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# На MNIST с таким порогом по тесту хватит и многослойного перцептрона\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()  # out.size() = [32, 784]\n",
        "    self.linear1 = nn.Linear(in_features=784, out_features=30)\n",
        "    self.linear2 = nn.Linear(in_features=30, out_features=20)\n",
        "    self.linear3 = nn.Linear(in_features=20, out_features=10)\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, img):\n",
        "    img = self.flatten(img)\n",
        "    img = self.act(self.linear1(img))\n",
        "    img = self.act(self.linear2(img))\n",
        "    img = self.linear3(img) # Без активации, потому что будем использовать nn.CrossEntropyLoss()\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "NZXV9vBLub-f"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_008Sq_TuAWw"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgH2eKpuuAWw"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "M8UKYYNyuAWx",
        "outputId": "8a7f6a27-a1b8-4150-cb1c-ae02e687117a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsSuePGLuAWx"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8yhlP-G2uAWx",
        "outputId": "c78f025d-8c91-489c-92f8-7920c3e9393c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear1): Linear(in_features=784, out_features=30, bias=True)\n",
              "  (linear2): Linear(in_features=30, out_features=20, bias=True)\n",
              "  (linear3): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (act): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = 'cpu'\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch():\n",
        "  model.train()\n",
        "\n",
        "  cur_loss = 0\n",
        "\n",
        "  for imgs, labels in train_data_loader:\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outs = model(imgs)\n",
        "    loss = loss_fn(outs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    cur_loss += loss.item()\n",
        "\n",
        "  return cur_loss / len(train_data_loader)"
      ],
      "metadata": {
        "id": "U7v39ZBq3VTO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  print('EPOCH {}:'.format(epoch + 1))\n",
        "  cur_train_loss = train_one_epoch()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  cur_val_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for imgs, labels in test_data_loader:\n",
        "\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        val_out = model(imgs)\n",
        "        cur_val_loss += loss_fn(val_out, labels).item()\n",
        "\n",
        "  cur_val_loss /= len(test_data_loader)\n",
        "\n",
        "  print('LOSS train {} valid {}'.format(cur_train_loss, cur_val_loss))"
      ],
      "metadata": {
        "id": "cFZEnOzi4saF",
        "outputId": "fa714258-53f9-42e6-802e-ac4d8a460508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "LOSS train 0.3583256425033013 valid 0.19998566892009956\n",
            "EPOCH 2:\n",
            "LOSS train 0.18438008577624956 valid 0.15207815938703598\n",
            "EPOCH 3:\n",
            "LOSS train 0.14313833460633954 valid 0.13177334645260186\n",
            "EPOCH 4:\n",
            "LOSS train 0.11861027745728692 valid 0.12484493156368383\n",
            "EPOCH 5:\n",
            "LOSS train 0.10687181552536786 valid 0.1201267162953078\n",
            "EPOCH 6:\n",
            "LOSS train 0.09631173171152671 valid 0.11242945076129325\n",
            "EPOCH 7:\n",
            "LOSS train 0.08532620428732286 valid 0.11889508089084869\n",
            "EPOCH 8:\n",
            "LOSS train 0.08006576600372792 valid 0.11855018414748898\n",
            "EPOCH 9:\n",
            "LOSS train 0.07521201438335702 valid 0.11865525982712177\n",
            "EPOCH 10:\n",
            "LOSS train 0.06907916121541832 valid 0.11430472700334803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijZ0Po9uAWx"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f56NKBdEuAWx"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rFQYp4qKuAWx"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "tSaufRvnuAWx",
        "outputId": "2e68c86c-f976-4e0f-a668-49a33128b1e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.98018\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hQc57rTouAWx"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gqXXxXPjuAWx",
        "outputId": "d00fc50e-bb4e-497f-fae3-65333ed9ea70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9678\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d3boLGFuAWy"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "xu3v5ZZ_uAWy"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Bze19muAWy"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EIRlFu_G71B-",
        "outputId": "defa6ae7-a32d-4a58-8583-84769f9c2bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ml_training_3_data/hw_mnist_data_dict.npy'"
      ],
      "metadata": {
        "id": "chYL-lHy76oK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "X-fRBwg8uAWy",
        "outputId": "08718c5b-a620-4e74-f820-88e7e23c6d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_mnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists(file_path), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_mnist_task_1.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pL9K08ouAWy"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLUBBAzquAWy"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}