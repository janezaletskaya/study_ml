{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "NiS3L09qVKvt"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlmDG--xVKvt"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR7WzQ7zVKvt",
        "outputId": "ec0c7eca-750b-445d-9e3d-e5c863e89374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 00:58:55--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-10 00:58:56--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-10 00:58:56 (93.4 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "P7nYQ4WrVKvt"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "id": "IhEM-tMoVKvu"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9UIyxQaVbJU",
        "outputId": "d2e441f0-0627-4168-9174-552b64e1d656"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global_mean = 0\n",
        "# for imgs, labels in train_data_loader:\n",
        "#   global_mean += imgs.sum()\n",
        "\n",
        "# global_mean /= len(train_fmnist_data) * 28 * 28\n",
        "\n",
        "# global_var = 0\n",
        "# for imgs, labels in train_data_loader:\n",
        "#   global_var += ((imgs - global_mean) ** 2).sum()\n",
        "\n",
        "# global_var /= len(train_fmnist_data) * 28 * 28\n",
        "# global_std = torch.sqrt(global_var)"
      ],
      "metadata": {
        "id": "SFjww6B0Vk9G"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_mean, global_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6k3vzXYV6ws",
        "outputId": "0dbce3d8-d675-4a84-a954-ffeab1adb040"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2860), tensor(0.3530))"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "aYcL28OsgSq8",
        "outputId": "d8231c85-80a2-4618-a20a-069aa95d2313"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 6')"
            ]
          },
          "metadata": {},
          "execution_count": 405
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # torchvision.transforms.Normalize(mean=[0.286], std=[0.353])\n",
        "])\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=transform, download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=transform, download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NxSQtjzGXPUm",
        "outputId": "629f0bb0-e413-4778-fc9a-ca394a6d1056"
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, dropout_p=0.3):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(-1, 128 * 3 * 3)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "BiroUtkYWWYI"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e80241-77ab-43b0-f601-70148576d331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1152, out_features=512, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "49ae254e-e20b-470a-9207-7eab2c39776e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cKNXOipGaVFD"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  epoch_all = 0\n",
        "  epoch_correct = 0\n",
        "\n",
        "  for imgs, labels in train_data_loader:\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outs = model(imgs)\n",
        "    loss = loss_fn(outs, labels)\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    preds = outs.argmax(-1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    batch_size = labels.size(0)\n",
        "    epoch_correct += correct\n",
        "    epoch_all += batch_size\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  epoch_accuracy = epoch_correct / epoch_all\n",
        "  epoch_loss = train_loss / len(train_data_loader)\n",
        "\n",
        "  return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# список названий классов FashionMNIST\n",
        "classes = [\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "]\n",
        "\n",
        "def evaluate_per_class_accuracy(preds, labels):\n",
        "    correct = [0] * 10\n",
        "    total = [0] * 10\n",
        "\n",
        "    for label, pred in zip(labels, preds):\n",
        "        total[label] += 1\n",
        "        if label == pred:\n",
        "            correct[label] += 1\n",
        "\n",
        "    for i in range(10):\n",
        "        if total[i] > 0:\n",
        "            acc = 100 * correct[i] / total[i]\n",
        "        else:\n",
        "            acc = 0.0\n",
        "        print(f\"Accuracy of class {i} ({classes[i]:13s}): {acc:.2f}% ({correct[i]}/{total[i]})\")\n",
        "\n",
        "\n",
        "def val_one_epoch(model, verbose=False):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    epoch_correct = 0\n",
        "    epoch_all = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_data_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outs = model(imgs)\n",
        "            val_loss += loss_fn(outs, labels).item()\n",
        "\n",
        "            preds = outs.argmax(dim=1)\n",
        "\n",
        "            epoch_correct += (preds == labels).sum().item()\n",
        "            epoch_all += labels.size(0)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    if verbose:\n",
        "      evaluate_per_class_accuracy(all_preds, all_labels)\n",
        "\n",
        "    epoch_loss = val_loss / len(test_data_loader)\n",
        "    epoch_accuracy = epoch_correct / epoch_all\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ],
      "metadata": {
        "id": "fPGtL30sbCrz"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_epochs, model, lr, verbose_val=False):\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    print('EPOCH {}:'.format(epoch + 1))\n",
        "    train_loss, train_acc = train_one_epoch(model, optimizer)\n",
        "    val_loss, val_acc = val_one_epoch(model, verbose_val)\n",
        "\n",
        "    print('Loss train {} valid {}'.format(train_loss, val_loss))\n",
        "    print('Accuracy train {} valid {}'.format(train_acc, val_acc))"
      ],
      "metadata": {
        "id": "E86aBf0gbXLf"
      },
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "id": "O84D6ON1lP9M"
      },
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "  dropout_p = trial.suggest_float('dropout', 0.2, 0.8)\n",
        "  optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
        "\n",
        "  model = MyModel(dropout_p).to(device)\n",
        "\n",
        "  if optimizer_name == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  else:\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(5):\n",
        "    train_one_epoch(model, optimizer)\n",
        "\n",
        "  val_loss, val_acc = val_one_epoch(model)\n",
        "\n",
        "  return val_acc"
      ],
      "metadata": {
        "id": "xuwEDRbQlWZ6"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "n_trials = 20\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "for _ in tqdm(range(n_trials), desc=\"Optuna trials\"):\n",
        "    study.optimize(objective, n_trials=1, catch=(Exception,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGHbpkEmlz_b",
        "outputId": "fc318a3b-70e2-4f85-d762-7206573b5c03"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-10 01:01:47,110] A new study created in memory with name: no-name-6ef05973-914e-48ee-8b98-b37c1cc8209c\n",
            "Optuna trials:   0%|          | 0/20 [00:00<?, ?it/s][I 2025-04-10 01:02:55,153] Trial 0 finished with value: 0.8697 and parameters: {'lr': 0.0009339363481812629, 'dropout': 0.3676157521207825, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.8697.\n",
            "Optuna trials:   5%|▌         | 1/20 [01:08<21:32, 68.04s/it][I 2025-04-10 01:04:05,840] Trial 1 finished with value: 0.9015 and parameters: {'lr': 5.9751277487908246e-05, 'dropout': 0.5369477144024106, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.9015.\n",
            "Optuna trials:  10%|█         | 2/20 [02:18<20:52, 69.60s/it][I 2025-04-10 01:05:16,327] Trial 2 finished with value: 0.9044 and parameters: {'lr': 0.005705362838079558, 'dropout': 0.3576673424976179, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.9044.\n",
            "Optuna trials:  15%|█▌        | 3/20 [03:29<19:50, 70.00s/it][I 2025-04-10 01:06:23,741] Trial 3 finished with value: 0.7502 and parameters: {'lr': 6.405501298498452e-05, 'dropout': 0.29525668822123674, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9044.\n",
            "Optuna trials:  20%|██        | 4/20 [04:36<18:23, 68.98s/it][I 2025-04-10 01:07:36,270] Trial 4 finished with value: 0.9008 and parameters: {'lr': 3.652447342925875e-05, 'dropout': 0.5636657771675109, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.9044.\n",
            "Optuna trials:  25%|██▌       | 5/20 [05:49<17:33, 70.26s/it][I 2025-04-10 01:08:44,871] Trial 5 finished with value: 0.7427 and parameters: {'lr': 7.208990454622858e-05, 'dropout': 0.5175297154273717, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9044.\n",
            "Optuna trials:  30%|███       | 6/20 [06:57<16:15, 69.70s/it][I 2025-04-10 01:09:52,658] Trial 6 finished with value: 0.8477 and parameters: {'lr': 0.0007598572512562256, 'dropout': 0.7388888560314957, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9044.\n",
            "Optuna trials:  35%|███▌      | 7/20 [08:05<14:57, 69.07s/it][I 2025-04-10 01:11:02,474] Trial 7 finished with value: 0.9072 and parameters: {'lr': 0.000210896887871243, 'dropout': 0.3338646103708083, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.9072.\n",
            "Optuna trials:  40%|████      | 8/20 [09:15<13:51, 69.31s/it][I 2025-04-10 01:12:13,412] Trial 8 finished with value: 0.8868 and parameters: {'lr': 1.5615830777886415e-05, 'dropout': 0.45205507434379777, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.9072.\n",
            "Optuna trials:  45%|████▌     | 9/20 [10:26<12:48, 69.82s/it][I 2025-04-10 01:13:22,935] Trial 9 finished with value: 0.9098 and parameters: {'lr': 0.002627433182928503, 'dropout': 0.6914396980068506, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.9098.\n",
            "Optuna trials:  50%|█████     | 10/20 [11:35<11:37, 69.73s/it][I 2025-04-10 01:14:32,571] Trial 10 finished with value: 0.8746 and parameters: {'lr': 0.008768538018991781, 'dropout': 0.7886196613780081, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.9098.\n",
            "Optuna trials:  55%|█████▌    | 11/20 [12:45<10:27, 69.70s/it][I 2025-04-10 01:15:42,875] Trial 11 finished with value: 0.9148 and parameters: {'lr': 0.0002503767523257571, 'dropout': 0.2193468787085307, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.9148.\n",
            "Optuna trials:  60%|██████    | 12/20 [13:55<09:19, 69.88s/it][I 2025-04-10 01:16:52,021] Trial 12 finished with value: 0.9136 and parameters: {'lr': 0.0015299889493344333, 'dropout': 0.20801923408019463, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.9148.\n",
            "Optuna trials:  65%|██████▌   | 13/20 [15:04<08:07, 69.66s/it][I 2025-04-10 01:18:02,236] Trial 13 finished with value: 0.9039 and parameters: {'lr': 0.0003422557178035984, 'dropout': 0.20325655755653943, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.9148.\n",
            "Optuna trials:  70%|███████   | 14/20 [16:15<06:58, 69.83s/it][I 2025-04-10 01:19:12,661] Trial 14 finished with value: 0.9194 and parameters: {'lr': 0.001392546520225299, 'dropout': 0.20448981102079739, 'optimizer': 'Adam'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials:  75%|███████▌  | 15/20 [17:25<05:50, 70.01s/it][I 2025-04-10 01:20:22,077] Trial 15 finished with value: 0.9164 and parameters: {'lr': 0.000238522170485151, 'dropout': 0.2676134245769233, 'optimizer': 'Adam'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials:  80%|████████  | 16/20 [18:34<04:39, 69.83s/it][I 2025-04-10 01:21:32,348] Trial 16 finished with value: 0.9183 and parameters: {'lr': 0.0005014627444780142, 'dropout': 0.42793014913751354, 'optimizer': 'Adam'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials:  85%|████████▌ | 17/20 [19:45<03:29, 69.96s/it][I 2025-04-10 01:22:42,138] Trial 17 finished with value: 0.9087 and parameters: {'lr': 0.0032211048593090265, 'dropout': 0.4482338904209735, 'optimizer': 'Adam'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials:  90%|█████████ | 18/20 [20:55<02:19, 69.91s/it][I 2025-04-10 01:23:49,297] Trial 18 finished with value: 0.8535 and parameters: {'lr': 0.0006997902515302057, 'dropout': 0.6203592690118218, 'optimizer': 'SGD'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials:  95%|█████████▌| 19/20 [22:02<01:09, 69.08s/it][I 2025-04-10 01:24:58,994] Trial 19 finished with value: 0.9132 and parameters: {'lr': 0.0017896279101047938, 'dropout': 0.4503718060706013, 'optimizer': 'Adam'}. Best is trial 14 with value: 0.9194.\n",
            "Optuna trials: 100%|██████████| 20/20 [23:11<00:00, 69.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEZEwrs6md2M",
        "outputId": "8bb2b50e-f359-48c7-a29d-c595f76a4128"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "{'lr': 0.001392546520225299, 'dropout': 0.20448981102079739, 'optimizer': 'Adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_1 = MyModel(study.best_trial.params['dropout'])"
      ],
      "metadata": {
        "id": "JbGr-_vjvvhP"
      },
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(5, model_task_1, study.best_trial.params['lr'], verbose_val=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l22Qj-hScHv2",
        "outputId": "8e20362c-5bf7-4494-ec38-d1ac27566e58"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "Accuracy of class 0 (T-shirt/top  ): 89.20% (892/1000)\n",
            "Accuracy of class 1 (Trouser      ): 98.70% (987/1000)\n",
            "Accuracy of class 2 (Pullover     ): 82.00% (820/1000)\n",
            "Accuracy of class 3 (Dress        ): 92.60% (926/1000)\n",
            "Accuracy of class 4 (Coat         ): 87.60% (876/1000)\n",
            "Accuracy of class 5 (Sandal       ): 98.30% (983/1000)\n",
            "Accuracy of class 6 (Shirt        ): 69.80% (698/1000)\n",
            "Accuracy of class 7 (Sneaker      ): 93.30% (933/1000)\n",
            "Accuracy of class 8 (Bag          ): 97.80% (978/1000)\n",
            "Accuracy of class 9 (Ankle boot   ): 97.60% (976/1000)\n",
            "Loss train 0.2622327025383711 valid 0.26420178338171196\n",
            "Accuracy train 0.9037666666666667 valid 0.9069\n",
            "EPOCH 2:\n",
            "Accuracy of class 0 (T-shirt/top  ): 76.00% (760/1000)\n",
            "Accuracy of class 1 (Trouser      ): 97.20% (972/1000)\n",
            "Accuracy of class 2 (Pullover     ): 78.70% (787/1000)\n",
            "Accuracy of class 3 (Dress        ): 93.50% (935/1000)\n",
            "Accuracy of class 4 (Coat         ): 91.20% (912/1000)\n",
            "Accuracy of class 5 (Sandal       ): 99.00% (990/1000)\n",
            "Accuracy of class 6 (Shirt        ): 78.70% (787/1000)\n",
            "Accuracy of class 7 (Sneaker      ): 94.60% (946/1000)\n",
            "Accuracy of class 8 (Bag          ): 98.70% (987/1000)\n",
            "Accuracy of class 9 (Ankle boot   ): 97.00% (970/1000)\n",
            "Loss train 0.21439390098253885 valid 0.25492340120406576\n",
            "Accuracy train 0.92105 valid 0.9046\n",
            "EPOCH 3:\n",
            "Accuracy of class 0 (T-shirt/top  ): 83.70% (837/1000)\n",
            "Accuracy of class 1 (Trouser      ): 98.10% (981/1000)\n",
            "Accuracy of class 2 (Pullover     ): 87.70% (877/1000)\n",
            "Accuracy of class 3 (Dress        ): 90.40% (904/1000)\n",
            "Accuracy of class 4 (Coat         ): 86.70% (867/1000)\n",
            "Accuracy of class 5 (Sandal       ): 98.70% (987/1000)\n",
            "Accuracy of class 6 (Shirt        ): 77.20% (772/1000)\n",
            "Accuracy of class 7 (Sneaker      ): 98.80% (988/1000)\n",
            "Accuracy of class 8 (Bag          ): 99.00% (990/1000)\n",
            "Accuracy of class 9 (Ankle boot   ): 91.00% (910/1000)\n",
            "Loss train 0.18511120021964114 valid 0.24866426820322252\n",
            "Accuracy train 0.93035 valid 0.9113\n",
            "EPOCH 4:\n",
            "Accuracy of class 0 (T-shirt/top  ): 87.60% (876/1000)\n",
            "Accuracy of class 1 (Trouser      ): 98.60% (986/1000)\n",
            "Accuracy of class 2 (Pullover     ): 83.70% (837/1000)\n",
            "Accuracy of class 3 (Dress        ): 90.90% (909/1000)\n",
            "Accuracy of class 4 (Coat         ): 88.80% (888/1000)\n",
            "Accuracy of class 5 (Sandal       ): 98.70% (987/1000)\n",
            "Accuracy of class 6 (Shirt        ): 77.20% (772/1000)\n",
            "Accuracy of class 7 (Sneaker      ): 98.00% (980/1000)\n",
            "Accuracy of class 8 (Bag          ): 99.10% (991/1000)\n",
            "Accuracy of class 9 (Ankle boot   ): 96.90% (969/1000)\n",
            "Loss train 0.16412060272966822 valid 0.23335774792149996\n",
            "Accuracy train 0.93925 valid 0.9195\n",
            "EPOCH 5:\n",
            "Accuracy of class 0 (T-shirt/top  ): 90.60% (906/1000)\n",
            "Accuracy of class 1 (Trouser      ): 98.50% (985/1000)\n",
            "Accuracy of class 2 (Pullover     ): 92.20% (922/1000)\n",
            "Accuracy of class 3 (Dress        ): 93.70% (937/1000)\n",
            "Accuracy of class 4 (Coat         ): 86.10% (861/1000)\n",
            "Accuracy of class 5 (Sandal       ): 97.40% (974/1000)\n",
            "Accuracy of class 6 (Shirt        ): 69.40% (694/1000)\n",
            "Accuracy of class 7 (Sneaker      ): 97.40% (974/1000)\n",
            "Accuracy of class 8 (Bag          ): 98.60% (986/1000)\n",
            "Accuracy of class 9 (Ankle boot   ): 96.90% (969/1000)\n",
            "Loss train 0.14342613226423662 valid 0.24170025070450796\n",
            "Accuracy train 0.9464166666666667 valid 0.9208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabb86d4-9bac-4ea5-9c5e-7c502ba30738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.96023\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa51cb7-6a58-46d0-90f1-999ab0b81213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9208\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nyxAaJtmhGEe"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uX6hOHqVKvv"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ml_training_3_data/hw_fmnist_data_dict.npy'"
      ],
      "metadata": {
        "id": "B_mhIp1uhJ5b"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_predictions(model, data):\n",
        "    n = data.shape[0]\n",
        "    random_preds = np.random.randint(0, 10, size=n)\n",
        "    return \",\".join(map(str, random_preds.tolist()))"
      ],
      "metadata": {
        "id": "P3fzp_t05S7R"
      },
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phq3BrzqVKvv",
        "outputId": "eda3bd39-92e2-4fcd-875b-9b573bb559f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    file_path\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(file_path, allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQrqY9zeVKvv"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}