{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7S7a8tjgZkR"
      },
      "source": [
        "## Homework: Multilingual Embedding-based Machine Translation (7 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuI1BuSGgZkS"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully).\n",
        "\n",
        "For our system we choose two kindred Slavic languages: Ukrainian and Russian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDVvFn4dgZkT"
      },
      "source": [
        "### Feel the difference!\n",
        "\n",
        "(_синій кіт_ vs. _синій кит_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRzbxP5VgZkU"
      },
      "source": [
        "![blue_cat_blue_whale.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/blue_cat_blue_whale.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvXVOtdFgZkU"
      },
      "source": [
        "### Fragment of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M16ZdmdogZkV"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more\n",
        "invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_LiqsvTgZkV"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy==1.23.5 gensim==4.3.2 scipy==1.10.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0HbQvw2Wg3qo",
        "outputId": "2ae33d43-14f2-44ac-db78-00ca84be4ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Requirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.2) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.2) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjhwdlj8gZkV"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TY3gaI4gZkW"
      },
      "source": [
        "Download embeddings here:\n",
        "* [cc.uk.300.vec.zip](https://yadi.sk/d/9CAeNsJiInoyUA)\n",
        "* [cc.ru.300.vec.zip](https://yadi.sk/d/3yG0-M4M8fypeQ)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rQXMG27uuec",
        "outputId": "7b4d0968-285c-4800-873c-bc398a90b1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path_ru = '/content/drive/My Drive/ru_uk_embeddings/cc.ru.300.vec.zip'\n",
        "zip_path_uk = '/content/drive/My Drive/ru_uk_embeddings/cc.uk.300.vec.zip'"
      ],
      "metadata": {
        "id": "GETQmOefvdgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/embeddings\n",
        "\n",
        "!unzip -q \"{zip_path_ru}\" -d \"/content/embeddings\"\n",
        "!unzip -q \"{zip_path_uk}\" -d \"/content/embeddings\""
      ],
      "metadata": {
        "id": "1DJKNp1tv7-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUn03h3_gZkW"
      },
      "source": [
        "Load embeddings for ukrainian and russian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6py9XedgZkX"
      },
      "outputs": [],
      "source": [
        "uk_emb = KeyedVectors.load_word2vec_format(\"/content/embeddings/cc.uk.300.vec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHTUQprIgZkX"
      },
      "outputs": [],
      "source": [
        "ru_emb = KeyedVectors.load_word2vec_format(\"/content/embeddings/cc.ru.300.vec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "838t5m21gZkX",
        "outputId": "f714aba7-dfb6-4a6e-d82a-c5d0ab78d3f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0000001192092896),\n",
              " ('июль', 0.9383152723312378),\n",
              " ('сентябрь', 0.9240029454231262),\n",
              " ('июнь', 0.9222574830055237),\n",
              " ('октябрь', 0.9095539450645447),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545795679092407),\n",
              " ('февраль', 0.8401415944099426)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hfjU63IgZkX",
        "outputId": "125b73fd-4724-43d3-e3a7-6d2c4e4ef360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999998807907104),\n",
              " ('липень', 0.9096441268920898),\n",
              " ('вересень', 0.9016969203948975),\n",
              " ('червень', 0.8992518782615662),\n",
              " ('жовтень', 0.8810408115386963),\n",
              " ('листопад', 0.8787633180618286),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.840811014175415),\n",
              " ('лютий', 0.8256431221961975)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhKuS7U9gZkX",
        "outputId": "13c673ee-3eef-4446-c150-c931b8b8f19b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Недопустимость', 0.24435284733772278),\n",
              " ('конструктивность', 0.23293082416057587),\n",
              " ('офор', 0.23256804049015045),\n",
              " ('deteydlya', 0.230317160487175),\n",
              " ('пресечении', 0.22632381319999695),\n",
              " ('одностороннего', 0.22608886659145355),\n",
              " ('подход', 0.2230587750673294),\n",
              " ('иболее', 0.22003726661205292),\n",
              " ('2015Александр', 0.21872766315937042),\n",
              " ('конструктивен', 0.21796567738056183)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX5Q_dwmgZkX"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPtkK9LkgZkX"
      },
      "outputs": [],
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/My Drive/ru_uk_embeddings/ukr_rus.train.txt'\n",
        "test_path = '/content/drive/My Drive/ru_uk_embeddings/ukr_rus.test.txt'"
      ],
      "metadata": {
        "id": "x-0QmwgEy2kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gw4Aky2gZkY"
      },
      "outputs": [],
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A70Yh6X-gZkY"
      },
      "outputs": [],
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWY_nfj8gZkY"
      },
      "source": [
        "## Embedding space mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrGL3Y5zgZkY"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm.\n",
        "\n",
        "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnoPj7tsgZkY"
      },
      "source": [
        "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENac3HsgZkY"
      },
      "source": [
        "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqEbXYYTgZkY"
      },
      "source": [
        "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "class EmbeddingMapping:\n",
        "\n",
        "    def __init__(self, source_emb, target_emb, word_pairs=None, W=None):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        source_emb (KeyedVectors): Исходные эмбеддинги (украинские)\n",
        "        target_emb (KeyedVectors): Целевые эмбеддинги (русские)\n",
        "        word_pairs (list): Список пар слов для обучения [(source_word, target_word)]\n",
        "        W (numpy.ndarray): Матрица линейного преобразования\n",
        "        \"\"\"\n",
        "        self.source_emb = source_emb\n",
        "        self.target_emb = target_emb\n",
        "        self.W = W\n",
        "\n",
        "    def fit(self, word_pairs):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        word_pairs (list): Список пар слов для обучения [(source_word, target_word)]\n",
        "        \"\"\"\n",
        "        X, Y = [], []\n",
        "        for source_word, target_word in word_pairs:\n",
        "            if source_word in self.source_emb and target_word in self.target_emb:\n",
        "                X.append(self.source_emb[source_word])\n",
        "                Y.append(self.target_emb[target_word])\n",
        "\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "\n",
        "        linreg = LinearRegression(fit_intercept=False)\n",
        "        linreg.fit(X, Y)\n",
        "        self.W = linreg.coef_.T\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, vectors):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        vectors (numpy.ndarray): Матрица векторов для преобразования\n",
        "\n",
        "        Returns:\n",
        "        numpy.ndarray: Преобразованные векторы\n",
        "        \"\"\"\n",
        "        if self.W is None:\n",
        "            raise ValueError(\"Mapping not trained yet\")\n",
        "\n",
        "        transformed = np.zeros((vectors.shape[0], self.W.shape[1]))\n",
        "        for i in range(vectors.shape[0]):\n",
        "            transformed[i] = vectors[i] @ self.W\n",
        "\n",
        "        return transformed"
      ],
      "metadata": {
        "id": "pgaGOFm5-lTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6iHwlwQgZkY"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Tf-BrUgZkY",
        "outputId": "595159da-7d3e-460f-8ad4-8fea17d11e19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8541285991668701),\n",
              " ('июнь', 0.8411202430725098),\n",
              " ('март', 0.839699387550354),\n",
              " ('сентябрь', 0.835986852645874),\n",
              " ('февраль', 0.8329297304153442),\n",
              " ('октябрь', 0.8311845660209656),\n",
              " ('ноябрь', 0.8278923630714417),\n",
              " ('июль', 0.8234528303146362),\n",
              " ('август', 0.812049925327301),\n",
              " ('декабрь', 0.803900420665741)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "mapping = EmbeddingMapping(uk_emb, ru_emb)\n",
        "mapping.fit(uk_ru_train)\n",
        "\n",
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxkdZrc7gZkY"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEGlZolJgZkZ"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK_5EslYgZkZ"
      },
      "outputs": [],
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "      nearest_neighbors = ru_emb.most_similar([mapped_vectors[i]], topn=topn)\n",
        "      for word, _ in nearest_neighbors:\n",
        "        if word == ru:\n",
        "          num_matches += 1\n",
        "          break\n",
        "\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0r79BVqgZkZ"
      },
      "outputs": [],
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_sG-5CAgZkZ"
      },
      "outputs": [],
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Smtf_NgZkZ"
      },
      "outputs": [],
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3aBfsbKgZkZ"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qsc4uLOgZkZ"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal.\n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB8ay6dLgZkZ"
      },
      "outputs": [],
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    A = X_train.T.dot(Y_train)\n",
        "    U, S, Vt = np.linalg.svd(A, full_matrices=False)\n",
        "    W_star = U.dot(Vt)\n",
        "\n",
        "    return W_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY7gSKazgZkZ"
      },
      "outputs": [],
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-EFwhRBgZkZ",
        "outputId": "88daa24d-5d48-4aee-8dd3-c898b6fcde75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8237906694412231),\n",
              " ('сентябрь', 0.8049713373184204),\n",
              " ('март', 0.8025653958320618),\n",
              " ('июнь', 0.8021842241287231),\n",
              " ('октябрь', 0.8001735806465149),\n",
              " ('ноябрь', 0.7934483289718628),\n",
              " ('февраль', 0.7914120554924011),\n",
              " ('июль', 0.7908109426498413),\n",
              " ('август', 0.7891016602516174),\n",
              " ('декабрь', 0.7686373591423035)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOjqSB5bgZkZ"
      },
      "outputs": [],
      "source": [
        "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
        "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping.W = W"
      ],
      "metadata": {
        "id": "3xAQPvefEyyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBTd8OYsgZkg"
      },
      "source": [
        "## UK-RU Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEzmhMmxgZkg"
      },
      "source": [
        "Now we are ready to make simple word-based translator: for each word in source language in shared embedding space we find the nearest in target language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzb05DMxgZkg"
      },
      "outputs": [],
      "source": [
        "fairy_tale_path = '/content/drive/My Drive/ru_uk_embeddings/fairy_tale.txt'\n",
        "\n",
        "with open(fairy_tale_path, \"r\") as inpf:\n",
        "    uk_sentences = [line.rstrip().lower() for line in inpf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4vUSxJdygZkg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\w+|[^\\w\\s]', sentence.lower())\n",
        "    ru_tokens = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if re.match(r'[а-яіїєґ]+', token):\n",
        "            if token in uk_emb:\n",
        "                uk_word_emb = uk_emb[token].reshape(1, -1)\n",
        "                ru_word_emb = mapping.predict(uk_word_emb)[0]\n",
        "                nearest_words = ru_emb.most_similar([ru_word_emb], topn=1)\n",
        "                ru_word = nearest_words[0][0]\n",
        "                ru_tokens.append(ru_word)\n",
        "            else:\n",
        "                ru_tokens.append(token)\n",
        "        else:\n",
        "            ru_tokens.append(token)\n",
        "\n",
        "    result = \"\"\n",
        "    for i, token in enumerate(ru_tokens):\n",
        "        if token in '.,;:!?)]}' and i > 0:\n",
        "            result += token\n",
        "        elif i > 0 and ru_tokens[i-1] in '([{':\n",
        "            result += token\n",
        "        elif i > 0:\n",
        "            result += \" \" + token\n",
        "        else:\n",
        "            result += token\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "LZFh23ywgZkg"
      },
      "outputs": [],
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1, 3\") == \"1, 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "k--KH_nugZkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ebb5ca1d-97ef-4d92-8d45-fda016ae1d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: лисичка - сестричка і вовк - панібрат\n",
            "dst: лисичка - сестричка и волк - панібрат\n",
            "\n",
            "src: як була собі лисичка та зробила хатку, та й живе. а це приходять холоди. от лисичка замерзла та й побігла в село вогню добувать, щоб витопити. прибігає до одної баби та й каже:\n",
            "dst: как была себе лисичка и сделала избушку, и и живет. а оно приходят морозы. из лисичка замерзла и и побежала во село огня добувать, чтобы витопити. прибегает к одной бабы и и говорит:\n",
            "\n",
            "src: — здорові були, бабусю! з неділею... позичте мені огню, я вам одслужу.\n",
            "dst: — здоровые были, бабушку! со воскресеньем... позичте мне огня, мной тебе одслужу.\n",
            "\n",
            "src: — добре, — каже, — лисичко - сестричко. сідай погрійся трохи, поки я пиріжечки повибираю з печі!\n",
            "dst: — хорошо, — говорит, — лисичко - сестричка. садись погрійся немного, пока мной пирожки повибираю со печи!\n",
            "\n",
            "src: а баба макові пиріжки пекла. от баба вибирає пиріжки та на столі кладе, щоб прохололи; а лисичка підгляділа та за пиріг, та з хати... виїла мачок із середини, а туди напхала сміттячка, стулила та й біжить.\n",
            "dst: а бабка маковые пирожки ада. из бабка выбирает пирожки и по столе кладет, чтобы прохололи; а лисичка підгляділа и за пирог, и со хаты... виїла мачок со середины, а туда напхала сміттячка, стулила и и бежит.\n",
            "\n",
            "src: от біжить, а хлопці товар женуть до води.\n",
            "dst: из бежит, а парни товар гонят к воды.\n",
            "\n",
            "src: — здорові були, хлопці!\n",
            "dst: — здоровые были, парни!\n",
            "\n",
            "src: — здорова, лисичко - сестричко!\n",
            "dst: — здоровая, лисичко - сестричка!\n",
            "\n",
            "src: — проміняйте мені бичка - третячка на маковий пиріжок!\n",
            "dst: — проміняйте мне бычка - третячка по маковый пирожок!\n",
            "\n",
            "src: — добре, — кажуть.\n",
            "dst: — хорошо, — дескать.\n",
            "\n",
            "src: — тільки, — каже, — тепер не їжте, а як я вибіжу з села, то тоді.\n",
            "dst: — только, — говорит, — теперь не ешьте, а как мной вибіжу со деревни, то тогда.\n",
            "\n",
            "src: от помінялись. лисичка за бичка — та в ліс. а хлопці до пиріжка — а там сміттянко.\n",
            "dst: из поменяются. лисичка за бычка — и во лес. а парни к пирожка — а там сміттянко.\n",
            "\n",
            "src: от прибігла лисичка до своєї хатки, вирубала дерево, зробила санки, запрягла бичка — іде. аж біжить вовк:\n",
            "dst: из прибежала лисичка к своего хатки, вирубала дерево, сделала санки, запрягла бычка — идет. аж бежит волк:\n",
            "\n",
            "src: — здорова, лисичко - сестричко!\n",
            "dst: — здоровая, лисичко - сестричка!\n",
            "\n",
            "src: — здоров, вовчику - братику!\n",
            "dst: — здоровье, вовчику - братику!\n",
            "\n",
            "src: — де ти взяла бичка - третячка і санки?\n",
            "dst: — куда ты взяла бычка - третячка и санки?\n",
            "\n",
            "src: — зробила собі!\n",
            "dst: — сделала себе!\n",
            "\n",
            "src: — підвези ж, — каже, — мене, лисичко - сестричко!\n",
            "dst: — підвези же, — говорит, — меня, лисичко - сестричка!\n",
            "\n",
            "src: — е, куди я тебе візьму? ти мені й санки поламаєш!\n",
            "dst: — ьн, куда мной тебя возьму? ты мне и санки поламаєш!\n",
            "\n",
            "src: — ні, — каже, — я тільки одну ніжку положу.\n",
            "dst: — ни, — говорит, — мной только одну ножку положу.\n",
            "\n",
            "src: — ну, клади!\n",
            "dst: — ну, дощечки!\n",
            "\n",
            "src: от од’їхали трохи, вовк і каже:\n",
            "dst: из от ’ ехали немного, волк и говорит:\n",
            "\n",
            "src: — положу я, лисичко - сестричко, й другу ніжку!\n",
            "dst: — положу мной, лисичко - сестричка, и вторую ножку!\n",
            "\n",
            "src: — е, вовчику - братику, ти мені й санки поламаєш!\n",
            "dst: — ьн, вовчику - братику, ты мне и санки поламаєш!\n",
            "\n",
            "src: — ні, — каже, — не поламаю!\n",
            "dst: — ни, — говорит, — не поламаю!\n",
            "\n",
            "src: — ну, клади!\n",
            "dst: — ну, дощечки!\n",
            "\n",
            "src: вовк і положив. ідуть, їдуть, коли це щось — трісь.\n",
            "dst: волк и положил. идут, едут, когда оно что-то — трісь.\n",
            "\n",
            "src: — е, вовчику - братику, ти мені вже й санки ламаєш!\n",
            "dst: — ьн, вовчику - братику, ты мне уже и санки ламаєш!\n",
            "\n",
            "src: — ні лисичко - сестричко, то я орішок розкусив.\n",
            "dst: — ни лисичко - сестричка, то мной орішок розкусив.\n",
            "\n",
            "src: — ну, гляди!\n",
            "dst: — ну, девки!\n",
            "\n",
            "src: от їдуть...\n",
            "dst: из едут...\n",
            "\n",
            "src: — положу я, лисичко - сестричко, й третю ніжку! — каже вовк.\n",
            "dst: — положу мной, лисичко - сестричка, и третью ножку! — говорит волк.\n",
            "\n",
            "src: — куди ти положиш? ти мені санки поламаєш! чим я тоді дровець привезу?\n",
            "dst: — куда ты положиш? ты мне санки поламаєш! Чем мной тогда дровець привезу?\n",
            "\n",
            "src: — ні, — каже, — не поламаю.\n",
            "dst: — ни, — говорит, — не поламаю.\n",
            "\n",
            "src: — ну, клади.\n",
            "dst: — ну, дощечки.\n",
            "\n",
            "src: вовк положив і третю ногу. коли це — трісь!\n",
            "dst: волк положил и третью ногу. когда оно — трісь!\n",
            "\n",
            "src: — ой лихо! — каже лисичка. — йди собі геть, вовчику, — ти мені зовсім санки поламаєш.\n",
            "dst: — ой горе! — говорит лисичка. — иди себе прочь, вовчику, — ты мне совсем санки поламаєш.\n",
            "\n",
            "src: — ні, то я орішок розкусив!\n",
            "dst: — ни, то мной орішок розкусив!\n",
            "\n",
            "src: — дай же й мені!\n",
            "dst: — дай то и мне!\n",
            "\n",
            "src: — нема, — каже, — останній!\n",
            "dst: — нету, — говорит, — последний!\n",
            "\n",
            "src: їдуть собі та й їдуть; вовчик і каже:\n",
            "dst: едут себе и и едут; вовчик и говорит:\n",
            "\n",
            "src: — сяду я зовсім, лисичко!\n",
            "dst: — сяду мной совсем, лисичко!\n",
            "\n",
            "src: — куди ти сядеш, вовчику - братику? і санки розламаєш!\n",
            "dst: — куда ты сяду, вовчику - братику? и санки розламаєш!\n",
            "\n",
            "src: — я помаленьку, — каже.\n",
            "dst: — мной потихоньку, — говорит.\n",
            "\n",
            "src: — ну, гляди!\n",
            "dst: — ну, девки!\n",
            "\n",
            "src: от вовчик тільки що сів, а санки так і розпались... лисичка тоді давай його лаять! лаяла - лаяла та й каже:\n",
            "dst: из вовчик только что уселся, а санки так и распались... лисичка тогда давай его лаять! ругала - ругала и и говорит:\n",
            "\n",
            "src: — піди ж, сякий - такий сину, дровець нарубай і на санки вирубай, і приволочи!\n",
            "dst: — пойди же, сякий - такой сыну, дровець нарубай и по санки вирубай, и приволочи!\n",
            "\n",
            "src: — як же я, — каже вовчик, — вирубаю, коли я не знаю, якого дерева?\n",
            "dst: — как то мной, — говорит вовчик, — вирубаю, когда мной не знаю, которого деревья?\n",
            "\n",
            "src: — е, — сякий - такий сину! як санчата ламать, так і знав, а дровець вирубать, то й ні!\n",
            "dst: — ьн, — сякий - такой сыну! как санки ламать, так и знал, а дровець вирубать, то и ни!\n",
            "\n",
            "src: коришувала його, коришувала...\n",
            "dst: коришувала его, коришувала...\n",
            "\n",
            "src: — як увійдеш, — каже, — в ліс, то кажи: « рубайся, дерево, й пряме, й криве! рубайся, дерево, й пряме, й криве! »\n",
            "dst: — как увійдеш, — говорит, — во лес, то говори: « рубайся, дерево, и прямое, и кривое! рубайся, дерево, и прямое, и кривое! »\n",
            "\n",
            "src: вовк і пішов.\n",
            "dst: волк и пошел.\n",
            "\n",
            "src: от приходить в ліс та й каже:\n",
            "dst: из приходит во лес и и говорит:\n",
            "\n",
            "src: — рубайся, дерево, криве й криве!\n",
            "dst: — рубайся, дерево, кривое и кривое!\n",
            "\n",
            "src: дерево й нарубалось. таке корячкувате, що й на палицю не вибереш — не то на полозок! приносить вовчик до лисички те дерево. вона як подивилась, давай його знов батькувати.\n",
            "dst: дерево и нарубалось. такое корячкувате, что и по палку не выберешь — не то по полозок! приносит вовчик к лисички что дерево. она как посмотрела, давай его снова батькувати.\n",
            "\n",
            "src: — ти, — каже, — сякий - такий сину, не так казав, як я тобі веліла!\n",
            "dst: — ты, — говорит, — сякий - такой сыну, не так говорил, как мной тебе велела!\n",
            "\n",
            "src: — ні, лисичко - сестричко, я, — каже, — стояв та все казав: « рубайся, дерево, криве й криве! »\n",
            "dst: — ни, лисичко - сестричка, мной, — говорит, — стоял и всё говорил: « рубайся, дерево, кривое и кривое! »\n",
            "\n",
            "src: — е, бісів сину, й того недотепний! ну, сиди ж ти тут, — я сама піду нарубаю.\n",
            "dst: — ьн, бесов сыну, и того недотепний! ну, сиди же ты здесь, — мной сама пойду нарубаю.\n",
            "\n",
            "src: та й пішла.\n",
            "dst: и и пошла.\n",
            "\n",
            "src: от сидить вовк сам собі — так їсти хочеться! він думав - думав: « давай, — каже, — з’їм бичка та й утечу! » от взяв проїв дірку у бичка, із середини все виїв, а туди горобців напустив і соломою заткнув, а сам — драла... приходить лисичка, зробила санчата, сіла...\n",
            "dst: из сидит волк сам себе — так кушать хочется! он думал - думал: « давай, — говорит, — со ’ им бычка и и побег! » из взял проїв дыру во бычка, со середины всё виїв, а туда воробьёв напустил и соломой заткнул, а сам — деру... приходит лисичка, сделала санки, присела...\n",
            "\n",
            "src: — гей, бичок - третячок!\n",
            "dst: — гей, бычок - третячок!\n",
            "\n",
            "src: аж бичок не везе. вона його батогом. як ударила, а віхоть соломи й випав; а горобці — хррр!\n",
            "dst: аж бычок не увозит. она его хлыстом. как ударила, а віхоть соломы и выпал; а воробьи — хррр!\n",
            "\n",
            "src: — а, сякий - такий вовчик! постій же, — каже, — я тобі згадаю!\n",
            "dst: — а, сякий - такой вовчик! постой то, — говорит, — мной тебе вспомню!\n",
            "\n",
            "src: та й пішла...\n",
            "dst: и и пошла...\n",
            "\n",
            "src: лягла на шляху та й лежить. ідуть чумаки з рибою; вона притаїлась, мов нежива. чумаки дивляться — аж лисиця:\n",
            "dst: легла по пути и и лежит. идут казаки со рыбой; она притаїлась, языки неживая. казаки смотрят — аж лисица:\n",
            "\n",
            "src: — візьмім, — кажуть, — бра, та продамо — буде за що хоч погрітися!\n",
            "dst: — візьмім, — дескать, — бра, и продадим — будет за что хоть погреться!\n",
            "\n",
            "src: скинули її на останній віз та й поїхали. ідуть та й їдуть. а лисичка - сестричка бачить, що вони не дивляться, та все кида по рибці на дорогу, все кида... от як накидала вже багато, тоді нишком і сама злізла. чумаки ж поїхали собі далі, а вона позбирала рибку, сіла та й їсть.\n",
            "dst: сбросили ей по последний визы и и поехали. идут и и едут. а лисичка - сестричка видит, что они не смотрят, и всё кида по рыбки по дорогу, всё кида... из как навязала уже много, тогда втихаря и сама слезла. казаки же поехали себе дальше, а она позбирала рыбку, присела и и ест.\n",
            "\n",
            "src: коли це біжить вовчик:\n",
            "dst: когда оно бежит вовчик:\n",
            "\n",
            "src: — здорова була, лисичко - сестричко!\n",
            "dst: — здоровая была, лисичко - сестричка!\n",
            "\n",
            "src: — здоров, вовчику - братику!\n",
            "dst: — здоровье, вовчику - братику!\n",
            "\n",
            "src: — що ти робиш, лисичко - сестричко?\n",
            "dst: — что ты делаешь, лисичко - сестричка?\n",
            "\n",
            "src: — рибу, — каже, — їм.\n",
            "dst: — рыбу, — говорит, — им.\n",
            "\n",
            "src: — дай же й мені!\n",
            "dst: — дай то и мне!\n",
            "\n",
            "src: — піди собі налови.\n",
            "dst: — пойди себе налови.\n",
            "\n",
            "src: — так як же я наловлю, коли я не вмію?\n",
            "dst: — так как то мной наловлю, когда мной не умею?\n",
            "\n",
            "src: — ну, як знаєш, а я не дам і кісточки!\n",
            "dst: — ну, как знаешь, а мной не дам и косточки!\n",
            "\n",
            "src: — так хоч навчи мене, як наловить.\n",
            "dst: — так хоть научить меня, как наловить.\n",
            "\n",
            "src: а лисичка й дума: « постій же! ти мого бичка - третячка з’їв — я тепер тобі оддячу! »\n",
            "dst: а лисичка и дума: « постой то! ты моего бычка - третячка со ’ ел — мной теперь тебе оддячу! »\n",
            "\n",
            "src: — а так, — каже, — піди до ополонки, устроми в ополонку хвіст та потихеньку води ним і приказуй: « ловись, рибко, мала й велика! ловись, рибко, мала й велика! » то вона й наловиться.\n",
            "dst: — а так, — говорит, — пойди к проруби, устроми во прорубь хвост и потихоньку воды ним и приказуй: « ловись, рыбка, имела и большая! ловись, рыбка, имела и большая! » то она и наловиться.\n",
            "\n",
            "src: — ну, спасибі за науку! — каже вовчик.\n",
            "dst: — ну, спасибо за науку! — говорит вовчик.\n",
            "\n",
            "src: от прибігає вовчик до ополонки, устромив в ополонку хвіст:\n",
            "dst: из прибегает вовчик к проруби, устромив во прорубь хвост:\n",
            "\n",
            "src: — ловись, — каже, — рибко, мала й велика!\n",
            "dst: — ловись, — говорит, — рыбка, имела и большая!\n",
            "\n",
            "src: а лисичка з очерету:\n",
            "dst: а лисичка со камыша:\n",
            "\n",
            "src: — мерзни, мерзни, вовчий хвіст!\n",
            "dst: — мерзни, мерзни, волчий хвост!\n",
            "\n",
            "src: а мороз надворі такий, що аж шкварчить! вовчик хвостиком усе водить та:\n",
            "dst: а мороз дворе такой, что аж шкварчить! вовчик хвостиком всё водит и:\n",
            "\n",
            "src: — ловись, рибко, мала й велика!\n",
            "dst: — ловись, рыбка, имела и большая!\n",
            "\n",
            "src: а лисичка:\n",
            "dst: а лисичка:\n",
            "\n",
            "src: — мерзни, мерзни, вовчий хвіст!\n",
            "dst: — мерзни, мерзни, волчий хвост!\n",
            "\n",
            "src: поки ловив вовчик рибу, поки хвіст так і прикипів в ополонці! тоді лисичка в село:\n",
            "dst: пока ловил вовчик рыбу, пока хвост так и пугаясь во проруби! тогда лисичка во село:\n",
            "\n",
            "src: — ідіть, люди, вовка бить!\n",
            "dst: — идите, люди, волка мочь!\n",
            "\n",
            "src: люди як вискочать — з кочергами, з рогачами, із сокирами: вбили того вовка і пропав бідний! а лисичка й досі живе у своїй хатці.\n",
            "dst: люди как вискочать — со кочергами, со рогачами, со топорами: убили того волка и пропал бедный! а лисичка и сих живет во своей хате.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaS5-H7gZkg"
      },
      "source": [
        "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QruB39bcgZkg"
      },
      "source": [
        "## Would you like to learn more?\n",
        "\n",
        "### Articles:\n",
        "* [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168)  - entry point for multilingual embedding studies by Tomas Mikolov (the author of W2V)\n",
        "* [Offline bilingual word vectors, orthogonal transformations and the inverted softmax](https://arxiv.org/pdf/1702.03859) - orthogonal transform for unsupervised MT\n",
        "* [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087)\n",
        "* [Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion](https://arxiv.org/pdf/1804.07745)\n",
        "* [Unsupervised Alignment of Embeddings with Wasserstein Procrustes](https://arxiv.org/pdf/1805.11222)\n",
        "\n",
        "### Repos (with ready-to-use multilingual embeddings):\n",
        "* https://github.com/facebookresearch/MUSE\n",
        "\n",
        "* https://github.com/Babylonpartners/fastText_multilingual -"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yDVvFn4dgZkT"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}